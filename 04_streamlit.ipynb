{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61906b2d-4d85-49c4-ade5-a77b6ad37df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ceb39d-e934-46c8-9736-82baa6e28781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.12/site-packages (19.0.1)\n",
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.12/site-packages (2024.10.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in /opt/conda/lib/python3.12/site-packages (from s3fs) (2.21.1)\n",
      "Requirement already satisfied: fsspec==2024.10.0.* in /opt/conda/lib/python3.12/site-packages (from s3fs) (2024.10.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.12/site-packages (from s3fs) (3.9.5)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /opt/conda/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (0.12.0)\n",
      "Requirement already satisfied: botocore<1.37.2,>=1.37.0 in /opt/conda/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.37.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.0.1)\n",
      "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /opt/conda/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (6.2.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /opt/conda/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.17.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.5.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.12/site-packages (from botocore<1.37.2,>=1.37.0->aiobotocore<3.0.0,>=2.5.4->s3fs) (2.3.0)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.12/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.10)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (0.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas pyarrow s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "368d21e3-e20a-4fb5-8509-4f58ce893917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           pickup_hour  pickup_location_id  rides  year  month\n",
      "0  2023-01-01 00:00:00                   2      0  2023      1\n",
      "1  2023-01-01 01:00:00                   2      0  2023      1\n",
      "2  2023-01-01 02:00:00                   2      0  2023      1\n",
      "3  2023-01-01 03:00:00                   2      0  2023      1\n",
      "4  2023-01-01 04:00:00                   2      0  2023      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import s3fs\n",
    "\n",
    "# Initialize S3 filesystem\n",
    "fs = s3fs.S3FileSystem(anon=False)\n",
    "\n",
    "# Define the base path and years/months\n",
    "base_path = \"jaath-buckets-0491f6b4-2be4-4ab9-9aa2-c62891ad4a9c/taxi/glue-transformed\"\n",
    "years = ['2023', '2024']\n",
    "months = [f\"{i:02d}\" for i in range(1, 13)]\n",
    "\n",
    "# Gather all matching file paths\n",
    "parquet_files = []\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        path = f\"{base_path}/year={year}/month={month}/\"\n",
    "        try:\n",
    "            files = fs.ls(path)\n",
    "            parquet_files.extend([\"s3://\" + f for f in files if f.endswith(\".parquet\") or f.endswith(\".snappy.parquet\")])\n",
    "        except FileNotFoundError:\n",
    "            # Skip months that don't exist\n",
    "            continue\n",
    "\n",
    "# Load all Parquet files into a single DataFrame\n",
    "df_list = []\n",
    "for file in parquet_files:\n",
    "    df = pq.ParquetDataset(file, filesystem=fs).read().to_pandas()\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all dataframes\n",
    "full_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "print(full_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e36d9ce7-5215-465f-973f-04f7013b463e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4394088 entries, 0 to 4394087\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Dtype \n",
      "---  ------              ----- \n",
      " 0   pickup_hour         object\n",
      " 1   pickup_location_id  int16 \n",
      " 2   rides               int16 \n",
      " 3   year                int32 \n",
      " 4   month               int32 \n",
      "dtypes: int16(2), int32(2), object(1)\n",
      "memory usage: 83.8+ MB\n"
     ]
    }
   ],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a011651-81a0-46fc-8e3d-c68c1e54ed02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Using cached psycopg2_binary-2.9.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: SQLAlchemy in /opt/conda/lib/python3.12/site-packages (2.0.39)\n",
      "Collecting SQLAlchemy\n",
      "  Using cached sqlalchemy-2.0.40-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.12/site-packages (from SQLAlchemy) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.12/site-packages (from SQLAlchemy) (4.12.2)\n",
      "Using cached psycopg2_binary-2.9.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached sqlalchemy-2.0.40-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Installing collected packages: SQLAlchemy, psycopg2-binary\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.39\n",
      "    Uninstalling SQLAlchemy-2.0.39:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.39\n",
      "Successfully installed SQLAlchemy-2.0.40 psycopg2-binary-2.9.10\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade psycopg2-binary SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70617782-55fb-410f-a46f-7b65f05ac4a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psycopg2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msqlalchemy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_engine, text\n\u001b[0;32m----> 3\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpostgresql+psycopg2://postgres:project#3password@rds-taxi.cst0aqomgoh3.us-east-1.rds.amazonaws.com:5432/postgres\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mconnect() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m      6\u001b[0m     result \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mexecute(text(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT version();\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/sqlalchemy/util/deprecations.py:281\u001b[0m, in \u001b[0;36mdeprecated_params.<locals>.decorate.<locals>.warned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    275\u001b[0m         _warn_with_version(\n\u001b[1;32m    276\u001b[0m             messages[m],\n\u001b[1;32m    277\u001b[0m             versions[m],\n\u001b[1;32m    278\u001b[0m             version_warnings[m],\n\u001b[1;32m    279\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    280\u001b[0m         )\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/sqlalchemy/engine/create.py:602\u001b[0m, in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    601\u001b[0m             dbapi_args[k] \u001b[38;5;241m=\u001b[39m pop_kwarg(k)\n\u001b[0;32m--> 602\u001b[0m     dbapi \u001b[38;5;241m=\u001b[39m \u001b[43mdbapi_meth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdbapi_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m dialect_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdbapi\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dbapi\n\u001b[1;32m    606\u001b[0m dialect_args\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiler_linting\u001b[39m\u001b[38;5;124m\"\u001b[39m, compiler\u001b[38;5;241m.\u001b[39mNO_LINTING)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py:696\u001b[0m, in \u001b[0;36mPGDialect_psycopg2.import_dbapi\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimport_dbapi\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[0;32m--> 696\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpsycopg2\u001b[39;00m\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m psycopg2\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'psycopg2'"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(\"postgresql+psycopg2://postgres:project#3password@rds-taxi.cst0aqomgoh3.us-east-1.rds.amazonaws.com:5432/postgres\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT version();\"))\n",
    "    print(result.fetchone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07197f3d-092b-4d6d-8f49-144439d4a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!aws configure get region\n",
    "create_sql = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS taxi_rides (\n",
    "    pickup_hour VARCHAR(20),\n",
    "    pickup_location_id SMALLINT,\n",
    "    rides SMALLINT,\n",
    "    year SMALLINT,\n",
    "    month SMALLINT\n",
    ");\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_sql))\n",
    "    conn.commit() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cc5dd61-5f30-4b7e-88e0-81475abe1a11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql('taxi_rides',con=engine,index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c8e3736-03d9-40e9-b7b8-5540b37232f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>rides</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-30 08:00:00</td>\n",
       "      <td>234</td>\n",
       "      <td>31</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-30 09:00:00</td>\n",
       "      <td>234</td>\n",
       "      <td>47</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-30 10:00:00</td>\n",
       "      <td>234</td>\n",
       "      <td>76</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-30 11:00:00</td>\n",
       "      <td>234</td>\n",
       "      <td>85</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-30 12:00:00</td>\n",
       "      <td>234</td>\n",
       "      <td>104</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_hour  pickup_location_id  rides  year month\n",
       "0  2024-12-30 08:00:00                 234     31  2024    12\n",
       "1  2024-12-30 09:00:00                 234     47  2024    12\n",
       "2  2024-12-30 10:00:00                 234     76  2024    12\n",
       "3  2024-12-30 11:00:00                 234     85  2024    12\n",
       "4  2024-12-30 12:00:00                 234    104  2024    12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_sql(\"SELECT * FROM taxi_rides LIMIT 5\",con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e30b357c-4cdb-4a95-bea2-75750d066063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Able to reach the database on port 5432\n"
     ]
    }
   ],
   "source": [
    "# check connection\n",
    "import socket\n",
    "host = \"taxi-db.cpkuaew6kys1.us-east-2.rds.amazonaws.com\"\n",
    "port = 5432\n",
    "try:\n",
    "    socket.create_connection((host, port), timeout=5)\n",
    "    print(\"✅ Able to reach the database on port 5432\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not connect: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "714568ce-ff1a-4262-a60f-fd50e4070e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "# Connect to default 'postgres' database to create a new one\n",
    "conn = psycopg2.connect(\n",
    "    dbname='postgres',\n",
    "    user='postgres',\n",
    "    password='project#3password',\n",
    "    host='rds-taxi.cst0aqomgoh3.us-east-1.rds.amazonaws.com',\n",
    "    port=5432\n",
    ")\n",
    "conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE DATABASE taxidata;\")\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515ef667-c959-4ce4-a4fb-e5b2ff14709d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "881e9bfd-520b-4a7c-bfe4-df1edbd42e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\n",
    "    \"postgresql+psycopg2://postgres:project#3password@rds-taxi.cst0aqomgoh3.us-east-1.rds.amazonaws.com:5432/postgres\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5616d-39a8-4e6b-9061-089cafb30b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df.to_sql('taxi_rides', con=engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83afc98-cd26-46b9-9808-a0e7c8f80d8b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pd.read_sql(\"SELECT * FROM taxi_rides LIMIT 5\",con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19df1e77-7157-4d28-8021-680ebeb92ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count\n",
       "0  20872"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_sql(\"SELECT count(*) FROM taxi_rides LIMIT 5;\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c00fd1a-6787-408e-99f3-1d7c4f19cce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   prediction_datetime  predicted_rides  pickup_location_id  year  month  day  \\\n",
      "0  2024-01-01 00:00:00               33                 132  2024      1    1   \n",
      "1  2024-01-01 01:00:00               62                 132  2024      1    1   \n",
      "2  2024-01-01 10:00:00               32                 132  2024      1    1   \n",
      "3  2024-01-01 11:00:00               56                 132  2024      1    1   \n",
      "4  2024-01-01 12:00:00               61                 132  2024      1    1   \n",
      "\n",
      "   hour  \n",
      "0     0  \n",
      "1     1  \n",
      "2    10  \n",
      "3    11  \n",
      "4    12  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import s3fs\n",
    "import re\n",
    "\n",
    "fs = s3fs.S3FileSystem()\n",
    "\n",
    "bucket_base = 'jaath-buckets-0491f6b4-2be4-4ab9-9aa2-c62891ad4a9c/taxi/test-predicted-values'\n",
    "years = ['2023', '2024']\n",
    "\n",
    "df_list = []\n",
    "\n",
    "# List all pickup_location_id folders\n",
    "location_paths = fs.ls(bucket_base)\n",
    "for loc_path in location_paths:\n",
    "    # Extract location ID from the folder name\n",
    "    loc_match = re.search(r'pickup_location_id=(\\d+)', loc_path)\n",
    "    if not loc_match:\n",
    "        continue\n",
    "    location_id = int(loc_match.group(1))\n",
    "\n",
    "    for year in years:\n",
    "        try:\n",
    "            months = fs.ls(f\"{loc_path}/year={year}\")\n",
    "            for month_path in months:\n",
    "                month_match = re.search(r'month=(\\d+)', month_path)\n",
    "                if not month_match:\n",
    "                    continue\n",
    "                month = int(month_match.group(1))\n",
    "                days = fs.ls(month_path)\n",
    "                for day_path in days:\n",
    "                    day_match = re.search(r'day=(\\d+)', day_path)\n",
    "                    if not day_match:\n",
    "                        continue\n",
    "                    day = int(day_match.group(1))\n",
    "                    hours = fs.ls(day_path)\n",
    "                    for hour_path in hours:\n",
    "                        hour_match = re.search(r'hour=(\\d+)', hour_path)\n",
    "                        if not hour_match:\n",
    "                            continue\n",
    "                        hour = int(hour_match.group(1))\n",
    "                        file_path = f\"{hour_path}/prediction.csv\"\n",
    "                        if fs.exists(file_path):\n",
    "                            df = pd.read_csv(f\"s3://{file_path}\")\n",
    "                            df['pickup_location_id'] = location_id\n",
    "                            df['year'] = int(year)\n",
    "                            df['month'] = month\n",
    "                            df['day'] = day\n",
    "                            df['hour'] = hour\n",
    "                            df_list.append(df)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "\n",
    "# Combine all data\n",
    "predictions_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Preview\n",
    "print(predictions_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "255c493f-6aa7-4dfd-b1fa-c779405af8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26352 entries, 0 to 26351\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   prediction_datetime  26352 non-null  object\n",
      " 1   predicted_rides      26352 non-null  int64 \n",
      " 2   pickup_location_id   26352 non-null  int64 \n",
      " 3   year                 26352 non-null  int64 \n",
      " 4   month                26352 non-null  int64 \n",
      " 5   day                  26352 non-null  int64 \n",
      " 6   hour                 26352 non-null  int64 \n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "predictions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b329494-01a7-4faf-bf91-f8ea33513b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "predictions_df['pickup_location_id'] = 43\n",
    "\n",
    "engine = create_engine(\n",
    "    \"postgresql+psycopg2://postgres:project#3password@rds-taxi.cst0aqomgoh3.us-east-1.rds.amazonaws.com:5432/postgres\"\n",
    ")\n",
    "\n",
    "# Load into a new table\n",
    "predictions_df.to_sql('predicted_rides', con=engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68044c07-7fd2-44e7-b3b8-2c812ec633a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_datetime</th>\n",
       "      <th>predicted_rides</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 01:00:00</td>\n",
       "      <td>62</td>\n",
       "      <td>43</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01 10:00:00</td>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01 11:00:00</td>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01 12:00:00</td>\n",
       "      <td>61</td>\n",
       "      <td>43</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26347</th>\n",
       "      <td>2024-12-31 05:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26348</th>\n",
       "      <td>2024-12-31 06:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26349</th>\n",
       "      <td>2024-12-31 07:00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26350</th>\n",
       "      <td>2024-12-31 08:00:00</td>\n",
       "      <td>34</td>\n",
       "      <td>43</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26351</th>\n",
       "      <td>2024-12-31 09:00:00</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26352 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       prediction_datetime  predicted_rides  pickup_location_id  year  month  \\\n",
       "0      2024-01-01 00:00:00               33                  43  2024      1   \n",
       "1      2024-01-01 01:00:00               62                  43  2024      1   \n",
       "2      2024-01-01 10:00:00               32                  43  2024      1   \n",
       "3      2024-01-01 11:00:00               56                  43  2024      1   \n",
       "4      2024-01-01 12:00:00               61                  43  2024      1   \n",
       "...                    ...              ...                 ...   ...    ...   \n",
       "26347  2024-12-31 05:00:00                2                  43  2024     12   \n",
       "26348  2024-12-31 06:00:00                7                  43  2024     12   \n",
       "26349  2024-12-31 07:00:00               22                  43  2024     12   \n",
       "26350  2024-12-31 08:00:00               34                  43  2024     12   \n",
       "26351  2024-12-31 09:00:00               39                  43  2024     12   \n",
       "\n",
       "       day  hour  \n",
       "0        1     0  \n",
       "1        1     1  \n",
       "2        1    10  \n",
       "3        1    11  \n",
       "4        1    12  \n",
       "...    ...   ...  \n",
       "26347   31     5  \n",
       "26348   31     6  \n",
       "26349   31     7  \n",
       "26350   31     8  \n",
       "26351   31     9  \n",
       "\n",
       "[26352 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d61697d7-991c-454e-834b-c65e60146475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_datetime</th>\n",
       "      <th>predicted_rides</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 01:00:00</td>\n",
       "      <td>62</td>\n",
       "      <td>43</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01 10:00:00</td>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01 11:00:00</td>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01 12:00:00</td>\n",
       "      <td>61</td>\n",
       "      <td>43</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction_datetime  predicted_rides  pickup_location_id  year  month  day  \\\n",
       "0  2024-01-01 00:00:00               33                  43  2024      1    1   \n",
       "1  2024-01-01 01:00:00               62                  43  2024      1    1   \n",
       "2  2024-01-01 10:00:00               32                  43  2024      1    1   \n",
       "3  2024-01-01 11:00:00               56                  43  2024      1    1   \n",
       "4  2024-01-01 12:00:00               61                  43  2024      1    1   \n",
       "\n",
       "   hour  \n",
       "0     0  \n",
       "1     1  \n",
       "2    10  \n",
       "3    11  \n",
       "4    12  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"SELECT * FROM predicted_rides LIMIT 5;\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68e6c734-427c-4379-9f6f-ae6743daa109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"\"\"\n",
    "        CREATE INDEX IF NOT EXISTS idx_taxi_rides_loc_hour\n",
    "        ON taxi_rides (pickup_location_id, pickup_hour);\n",
    "    \"\"\"))\n",
    "\n",
    "    conn.execute(text(\"\"\"\n",
    "        CREATE INDEX IF NOT EXISTS idx_predicted_rides_loc_datetime\n",
    "        ON predicted_rides (pickup_location_id, prediction_datetime);\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5afa7ab4-4fd7-45d0-9dfe-e6c28b8e4172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Using cached streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.12/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.12/site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.12/site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /opt/conda/lib/python3.12/site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in /opt/conda/lib/python3.12/site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /opt/conda/lib/python3.12/site-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /opt/conda/lib/python3.12/site-packages (from streamlit) (5.28.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /opt/conda/lib/python3.12/site-packages (from streamlit) (19.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /opt/conda/lib/python3.12/site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /opt/conda/lib/python3.12/site-packages (from streamlit) (9.0.0)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /opt/conda/lib/python3.12/site-packages (from streamlit) (4.12.2)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Using cached watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/conda/lib/python3.12/site-packages (from streamlit) (3.1.44)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.12/site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /opt/conda/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (1.31.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Using cached streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
      "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "Installing collected packages: watchdog, toml, pydeck, streamlit\n",
      "Successfully installed pydeck-0.9.1 streamlit-1.44.1 toml-0.10.2 watchdog-6.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "365a713d-ef2d-4372-a3b1-1bf649ac7373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19 04:31:39.251 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-04-19 04:31:39.253 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.355 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/conda/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-04-19 04:31:39.357 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.359 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.361 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.363 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.363 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.364 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.365 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.367 Session state does not function when running a script without `streamlit run`\n",
      "2025-04-19 04:31:39.368 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.369 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.374 No runtime found, using MemoryCacheStorageManager\n",
      "2025-04-19 04:31:39.375 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.376 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.379 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.586 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.587 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.588 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.589 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.594 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.596 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.597 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.598 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.599 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.600 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.601 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.602 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.609 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-19 04:31:39.610 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# import streamlit as st\n",
    "# import pandas as pd\n",
    "# import plotly.express as px\n",
    "# import boto3\n",
    "# import time\n",
    "# from datetime import datetime, timedelta\n",
    "# from zoneinfo import ZoneInfo\n",
    "\n",
    "# # -----------------------\n",
    "# # Athena Query Function\n",
    "# # -----------------------\n",
    "# @st.cache_data\n",
    "# def run_athena_query(hour, query: str, database: str, s3_output: str) -> pd.DataFrame:\n",
    "#     athena_client = boto3.client('athena', region_name=\"us-east-1\")\n",
    "\n",
    "#     response = athena_client.start_query_execution(\n",
    "#         QueryString=query,\n",
    "#         QueryExecutionContext={'Database': database},\n",
    "#         ResultConfiguration={'OutputLocation': s3_output}\n",
    "#     )\n",
    "\n",
    "#     query_execution_id = response['QueryExecutionId']\n",
    "#     state = 'RUNNING'\n",
    "\n",
    "#     while state in ['RUNNING', 'QUEUED']:\n",
    "#         response = athena_client.get_query_execution(QueryExecutionId=query_execution_id)\n",
    "#         state = response['QueryExecution']['Status']['State']\n",
    "#         if state in ['RUNNING', 'QUEUED']:\n",
    "#             time.sleep(1)\n",
    "\n",
    "#     if state != 'SUCCEEDED':\n",
    "#         reason = response['QueryExecution']['Status'].get('StateChangeReason', 'Unknown')\n",
    "#         raise Exception(f\"Athena query failed: {state} - {reason}\")\n",
    "\n",
    "#     results = []\n",
    "#     columns = []\n",
    "#     next_token = None\n",
    "#     first_page = True\n",
    "\n",
    "#     while True:\n",
    "#         if next_token:\n",
    "#             result_set = athena_client.get_query_results(\n",
    "#                 QueryExecutionId=query_execution_id,\n",
    "#                 NextToken=next_token\n",
    "#             )\n",
    "#         else:\n",
    "#             result_set = athena_client.get_query_results(QueryExecutionId=query_execution_id)\n",
    "\n",
    "#         if first_page:\n",
    "#             columns = [col['Label'] for col in result_set['ResultSet']['ResultSetMetadata']['ColumnInfo']]\n",
    "#             first_page = False\n",
    "\n",
    "#         rows = result_set['ResultSet']['Rows']\n",
    "#         if next_token is None:\n",
    "#             rows = rows[1:]  # skip header\n",
    "\n",
    "#         for row in rows:\n",
    "#             results.append([field.get('VarCharValue', '') for field in row['Data']])\n",
    "\n",
    "#         next_token = result_set.get('NextToken')\n",
    "#         if not next_token:\n",
    "#             break\n",
    "\n",
    "#     df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "#     for col in df.columns:\n",
    "#         try:\n",
    "#             df[col] = pd.to_datetime(df[col])\n",
    "#         except:\n",
    "#             try:\n",
    "#                 df[col] = pd.to_numeric(df[col])\n",
    "#             except:\n",
    "#                 pass\n",
    "\n",
    "#     return df\n",
    "\n",
    "# # -----------------------\n",
    "# # Streamlit App\n",
    "# # -----------------------\n",
    "# st.title(\"NYC Taxi Rides Forecast\")\n",
    "\n",
    "# # Tabs\n",
    "# tab1, tab2 = st.tabs([\"Athena\", \"RDS\"])\n",
    "\n",
    "# # -----------------------\n",
    "# # Tab: Athena\n",
    "# # -----------------------\n",
    "# with tab1:\n",
    "#     # Pickup Location Input\n",
    "#     location_id = st.number_input(\"Enter Pickup Location ID\", min_value=1, max_value=300, value=43)\n",
    "\n",
    "#     # Use Eastern Time (New York)\n",
    "#     eastern = ZoneInfo(\"America/New_York\")\n",
    "#     now_ny = datetime.now(tz=eastern)\n",
    "\n",
    "#     # Calculate the same week last year in NY time\n",
    "#     end_date = now_ny - timedelta(days=358)\n",
    "#     start_date = now_ny - timedelta(days=365)\n",
    "\n",
    "#     # Round down to start of the hour\n",
    "#     start_rounded = start_date.replace(minute=0, second=0, microsecond=0)\n",
    "\n",
    "#     # Round up to next full hour if needed\n",
    "#     if end_date.minute > 0 or end_date.second > 0 or end_date.microsecond > 0:\n",
    "#         end_rounded = (end_date + timedelta(hours=1)).replace(minute=0, second=0, microsecond=0)\n",
    "#     else:\n",
    "#         end_rounded = end_date.replace(minute=0, second=0, microsecond=0)\n",
    "\n",
    "#     # Format for Athena query (still using naive-looking string)\n",
    "#     start_str = start_rounded.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "#     end_str = end_rounded.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "#     # Athena setup\n",
    "#     s3_output = 's3://mkzia-e4d44080-fbfa-41ff-9fca-3aaf9c307667/athena/'\n",
    "\n",
    "#     # Queries\n",
    "#     actual_query = f\"\"\"\n",
    "#     SELECT DISTINCT\n",
    "#         pickup_hour,\n",
    "#         rides\n",
    "#     FROM glue_transformed\n",
    "#     WHERE\n",
    "#         pickup_location_id = {location_id}\n",
    "#         AND pickup_hour BETWEEN '{start_str}' AND '{end_str}'\n",
    "#     ORDER BY pickup_hour;\n",
    "#     \"\"\"\n",
    "\n",
    "#     predicted_query = f\"\"\"\n",
    "#     SELECT DISTINCT\n",
    "#         prediction_datetime,\n",
    "#         predicted_rides\n",
    "#     FROM test_predicted_values\n",
    "#     WHERE\n",
    "#         pickup_location_id = '{location_id}'\n",
    "#         AND prediction_datetime BETWEEN '{start_str}' AND '{end_str}'\n",
    "#     ORDER BY prediction_datetime;\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Run Queries\n",
    "#     try:\n",
    "#         actual_df = run_athena_query(now_ny.hour, actual_query, 'etl_taxi_transformed', s3_output)\n",
    "#         predicted_df = run_athena_query(now_ny.hour, predicted_query, 'taxi_predictions', s3_output)\n",
    "\n",
    "#         # Plot\n",
    "#         fig = px.line()\n",
    "#         fig.add_scatter(x=actual_df['pickup_hour'], y=actual_df['rides'], name='Actual Rides')\n",
    "#         fig.add_scatter(x=predicted_df['prediction_datetime'], y=predicted_df['predicted_rides'], name='Predicted Rides')\n",
    "#         fig.update_layout(title=f\"Taxi Rides Forecast for Location {location_id}\",\n",
    "#                           xaxis_title=\"Time\",\n",
    "#                           yaxis_title=\"Number of Rides\")\n",
    "\n",
    "#         st.plotly_chart(fig)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         st.error(f\"❌ Error fetching data: {e}\")\n",
    "\n",
    "# # -----------------------\n",
    "# # Tab: RDS\n",
    "# # -----------------------\n",
    "# with tab2:\n",
    "#     st.subheader(\"RDS: Actual vs Predicted Rides\")\n",
    "\n",
    "#     # Pickup Location Input\n",
    "#     location_id_rds = st.number_input(\"Pickup Location ID (RDS)\", min_value=1, max_value=300, value=43, key=\"rds_loc\")\n",
    "\n",
    "#     # RDS connection settings\n",
    "#     import sqlalchemy\n",
    "#     from sqlalchemy import create_engine, text\n",
    "\n",
    "#     rds_host = \"taxi-db.clgo2ekc87nr.us-east-1.rds.amazonaws.com\"\n",
    "#     rds_db = \"taxidata\"\n",
    "#     rds_user = \"taxiuser\"\n",
    "#     rds_password = \"Saucy-Cultural-Iguana-Decibel-Residence3\"\n",
    "#     rds_port = 5432\n",
    "\n",
    "#     # Create engine\n",
    "#     rds_engine = create_engine(\n",
    "#         f\"postgresql+psycopg2://{rds_user}:{rds_password}@{rds_host}:{rds_port}/{rds_db}\"\n",
    "#     )\n",
    "\n",
    "#     # Use same time range\n",
    "#     try:\n",
    "#         with rds_engine.connect() as conn:\n",
    "#             actual_sql = text(f\"\"\"\n",
    "#                 SELECT pickup_hour, rides\n",
    "#                 FROM taxi_rides\n",
    "#                 WHERE pickup_location_id = :loc\n",
    "#                 AND pickup_hour BETWEEN :start AND :end\n",
    "#                 ORDER BY pickup_hour;\n",
    "#             \"\"\")\n",
    "#             predicted_sql = text(f\"\"\"\n",
    "#                 SELECT prediction_datetime, predicted_rides\n",
    "#                 FROM predicted_rides\n",
    "#                 WHERE pickup_location_id = :loc\n",
    "#                 AND prediction_datetime BETWEEN :start AND :end\n",
    "#                 ORDER BY prediction_datetime;\n",
    "#             \"\"\")\n",
    "\n",
    "#             actual_df_rds = pd.read_sql(actual_sql, conn, params={\n",
    "#                 'loc': location_id_rds,\n",
    "#                 'start': start_str,\n",
    "#                 'end': end_str\n",
    "#             })\n",
    "\n",
    "#             predicted_df_rds = pd.read_sql(predicted_sql, conn, params={\n",
    "#                 'loc': location_id_rds,\n",
    "#                 'start': start_str,\n",
    "#                 'end': end_str\n",
    "#             })\n",
    "\n",
    "#             # Plot\n",
    "#             fig_rds = px.line()\n",
    "#             fig_rds.add_scatter(x=actual_df_rds['pickup_hour'], y=actual_df_rds['rides'], name='Actual Rides')\n",
    "#             fig_rds.add_scatter(x=predicted_df_rds['prediction_datetime'], y=predicted_df_rds['predicted_rides'], name='Predicted Rides')\n",
    "#             fig_rds.update_layout(title=f\"RDS - Taxi Rides Forecast for Location {location_id_rds}\",\n",
    "#                                   xaxis_title=\"Time\",\n",
    "#                                   yaxis_title=\"Number of Rides\")\n",
    "#             st.plotly_chart(fig_rds)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         st.error(f\"❌ Error connecting to RDS: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1d92578-6deb-4295-ac94-43d790eaa65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime, timedelta\n",
    "# from zoneinfo import ZoneInfo\n",
    "# eastern = ZoneInfo(\"America/New_York\")\n",
    "# now_ny = datetime.now(tz=eastern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0db76df-cbb7-4027-b55d-a824ec05c99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now_ny.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36055fea-6fdb-4be9-a413-2d44a0eee8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully!\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# RDS connection settings\n",
    "rds_host = \"rds-taxi.cst0aqomgoh3.us-east-1.rds.amazonaws.com\"\n",
    "rds_db = \"postgres\"\n",
    "rds_user = \"postgres\"\n",
    "rds_password = \"project#3password\"\n",
    "rds_port = 5432\n",
    "\n",
    "# Create engine\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://{rds_user}:{rds_password}@{rds_host}:{rds_port}/{rds_db}\"\n",
    ")\n",
    "\n",
    "# Create the predicted_rides table with proper structure\n",
    "create_table_sql = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS predicted_rides (\n",
    "    pickup_location_id SMALLINT,\n",
    "    prediction_datetime TIMESTAMP,\n",
    "    predicted_rides SMALLINT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table_sql))\n",
    "    conn.commit()\n",
    "    print(\"Table created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07f7bb2a-42a4-45ee-93fc-f6aa76a7091e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26352 records to predicted_rides table\n"
     ]
    }
   ],
   "source": [
    "# First convert your DataFrame columns to the appropriate format\n",
    "if 'predictions_df' in locals() and not predictions_df.empty:\n",
    "    # Make sure prediction_datetime is in timestamp format\n",
    "    if 'prediction_datetime' not in predictions_df.columns:\n",
    "        # If not already present, create it from year, month, day, hour\n",
    "        predictions_df['prediction_datetime'] = pd.to_datetime(\n",
    "            predictions_df[['year', 'month', 'day', 'hour']].astype(str).agg('-'.join, axis=1)\n",
    "        )\n",
    "    \n",
    "    # Select only the relevant columns for the database\n",
    "    predicted_rides_df = predictions_df[['pickup_location_id', 'prediction_datetime', 'predicted_rides']]\n",
    "    \n",
    "    # Load to database\n",
    "    predicted_rides_df.to_sql('predicted_rides', con=engine, if_exists='replace', index=False)\n",
    "    print(f\"Loaded {len(predicted_rides_df)} records to predicted_rides table\")\n",
    "else:\n",
    "    print(\"No data available to load into the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41f1b371-952f-40c5-8599-d8512f7d9e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available databases:\n",
      "- predictions\n",
      "- taxi_db1\n",
      "- taxi_db2_fil\n",
      "- taxi_db_2324\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Create Athena client\n",
    "athena_client = boto3.client('athena', region_name=\"us-east-1\")\n",
    "\n",
    "# List available databases\n",
    "list_databases_query = \"SHOW DATABASES\"\n",
    "response = athena_client.start_query_execution(\n",
    "    QueryString=list_databases_query,\n",
    "    ResultConfiguration={'OutputLocation': 's3://jaath-buckets-0491f6b4-2be4-4ab9-9aa2-c62891ad4a9c/athena/'}\n",
    ")\n",
    "\n",
    "# Get the query results\n",
    "query_execution_id = response['QueryExecutionId']\n",
    "state = 'RUNNING'\n",
    "\n",
    "# Wait for query to complete\n",
    "while state in ['RUNNING', 'QUEUED']:\n",
    "    response = athena_client.get_query_execution(QueryExecutionId=query_execution_id)\n",
    "    state = response['QueryExecution']['Status']['State']\n",
    "    if state in ['RUNNING', 'QUEUED']:\n",
    "        import time\n",
    "        time.sleep(1)\n",
    "\n",
    "# Get results\n",
    "if state == 'SUCCEEDED':\n",
    "    results = athena_client.get_query_results(QueryExecutionId=query_execution_id)\n",
    "    databases = []\n",
    "    for row in results['ResultSet']['Rows'][1:]:  # Skip header\n",
    "        databases.append(row['Data'][0]['VarCharValue'])\n",
    "    print(\"Available databases:\")\n",
    "    for db in databases:\n",
    "        print(f\"- {db}\")\n",
    "else:\n",
    "    print(f\"Query failed: {response['QueryExecution']['Status'].get('StateChangeReason', 'Unknown reason')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b23ddbae-872a-4b9b-9b57-ae38f8e46d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records in taxi_rides: 20872\n",
      "Records for location 43: 0\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(\n",
    "    \"postgresql+psycopg2://postgres:project#3password@rds-taxi.cst0aqomgoh3.us-east-1.rds.amazonaws.com:5432/postgres\"\n",
    ")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT COUNT(*) FROM taxi_rides\"))\n",
    "    print(f\"Records in taxi_rides: {result.fetchone()[0]}\")\n",
    "    \n",
    "    # Check for actual data with your specific location ID\n",
    "    location_check = conn.execute(text(\n",
    "        \"SELECT COUNT(*) FROM taxi_rides WHERE pickup_location_id = 43\"\n",
    "    ))\n",
    "    print(f\"Records for location 43: {location_check.fetchone()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6eae94f-5e26-41ac-a3b3-d2b1a244a82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available location IDs: [239, 235, 257, 240, 258, 247, 260, 254, 248, 244]\n"
     ]
    }
   ],
   "source": [
    "# Find a location ID that has data\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT DISTINCT pickup_location_id FROM taxi_rides LIMIT 10\"))\n",
    "    locations = [row[0] for row in result]\n",
    "    print(f\"Available location IDs: {locations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea62bf8c-de72-4f92-ac69-20a046f593a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location 239 has 744 records from 2024-12-01 00:00:00 to 2024-12-31 23:00:00\n",
      "Location 239 has 0 predicted records\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    # Check if there's any data for location 239\n",
    "    result = conn.execute(text(\"\"\"\n",
    "        SELECT MIN(pickup_hour), MAX(pickup_hour), COUNT(*) \n",
    "        FROM taxi_rides \n",
    "        WHERE pickup_location_id = 239\n",
    "    \"\"\"))\n",
    "    min_date, max_date, count = result.fetchone()\n",
    "    print(f\"Location 239 has {count} records from {min_date} to {max_date}\")\n",
    "    \n",
    "    # Check if your predicted_rides table has data\n",
    "    result = conn.execute(text(\"\"\"\n",
    "        SELECT COUNT(*) FROM predicted_rides\n",
    "        WHERE pickup_location_id = 239\n",
    "    \"\"\"))\n",
    "    pred_count = result.fetchone()[0]\n",
    "    print(f\"Location 239 has {pred_count} predicted records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c666f480-1ed3-4c5b-bffa-9027e34443d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in database: ['predicted_rides', 'taxi_rides']\n",
      "\n",
      "Columns in predicted_rides:\n",
      "  pickup_location_id (bigint)\n",
      "  prediction_datetime (text)\n",
      "  predicted_rides (bigint)\n",
      "\n",
      "Columns in taxi_rides:\n",
      "  pickup_hour (text)\n",
      "  pickup_location_id (smallint)\n",
      "  rides (smallint)\n",
      "  year (text)\n",
      "  month (text)\n"
     ]
    }
   ],
   "source": [
    "# from sqlalchemy import text\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Connect to your database\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://postgres:project#3password@rds-taxi.cst0aqomgoh3.us-east-1.rds.amazonaws.com:5432/postgres\"\n",
    ")\n",
    "\n",
    "# List all tables in the database\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"\"\"\n",
    "        SELECT table_name \n",
    "        FROM information_schema.tables \n",
    "        WHERE table_schema = 'public'\n",
    "        ORDER BY table_name;\n",
    "    \"\"\"))\n",
    "    tables = [row[0] for row in result]\n",
    "    print(\"Tables in database:\", tables)\n",
    "\n",
    "    # For each table, show its columns\n",
    "    for table in tables:\n",
    "        result = conn.execute(text(f\"\"\"\n",
    "            SELECT column_name, data_type \n",
    "            FROM information_schema.columns \n",
    "            WHERE table_name = '{table}'\n",
    "            ORDER BY ordinal_position;\n",
    "        \"\"\"))\n",
    "        columns = [(row[0], row[1]) for row in result]\n",
    "        print(f\"\\nColumns in {table}:\")\n",
    "        for col, dtype in columns:\n",
    "            print(f\"  {col} ({dtype})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c2eadf5-ae44-4148-a304-97bf9c5b2930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime  # Added this line\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def generate_sample_data(location_ids=[43, 74, 132]):\n",
    "    \"\"\"Generate and load sample data for specified location IDs\"\"\"\n",
    "    # Connection to the database\n",
    "    rds_host = \"rds-taxi.cst0aqomgoh3.us-east-1.rds.amazonaws.com\"\n",
    "    rds_db = \"postgres\"\n",
    "    rds_user = \"postgres\"\n",
    "    rds_password = \"project#3password\"\n",
    "    rds_port = 5432\n",
    "    \n",
    "    # Create engine\n",
    "    engine = create_engine(\n",
    "        f\"postgresql+psycopg2://{rds_user}:{rds_password}@{rds_host}:{rds_port}/{rds_db}\"\n",
    "    )\n",
    "    \n",
    "    # Generate data for each location\n",
    "    for location_id in location_ids:\n",
    "        # Create time periods for the past 7 days with hourly data\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=7)\n",
    "        \n",
    "        date_range = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "        \n",
    "        # Generate actual data with a daily pattern\n",
    "        actual_data = []\n",
    "        for dt in date_range:\n",
    "            # Create a daily pattern with peak hours\n",
    "            hour = dt.hour\n",
    "            if 7 <= hour <= 9 or 16 <= hour <= 18:  # Morning and evening peaks\n",
    "                ride_count = np.random.randint(100, 200)\n",
    "            elif 0 <= hour <= 5:  # Night lows\n",
    "                ride_count = np.random.randint(0, 20)\n",
    "            else:  # Regular hours\n",
    "                ride_count = np.random.randint(30, 100)\n",
    "                \n",
    "            actual_data.append({\n",
    "                'pickup_hour': dt.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'pickup_location_id': location_id,\n",
    "                'rides': ride_count,\n",
    "                'year': str(dt.year),\n",
    "                'month': str(dt.month)\n",
    "            })\n",
    "        \n",
    "        # Generate predicted data with slight variation from actual\n",
    "        predicted_data = []\n",
    "        for row in actual_data:\n",
    "            dt = pd.to_datetime(row['pickup_hour'])\n",
    "            # Add some random variation to make predictions slightly different\n",
    "            predicted_ride_count = int(row['rides'] * (1 + np.random.uniform(-0.2, 0.2)))\n",
    "            predicted_data.append({\n",
    "                'pickup_location_id': location_id,\n",
    "                'prediction_datetime': dt.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'predicted_rides': max(0, predicted_ride_count)  # Ensure non-negative\n",
    "            })\n",
    "        \n",
    "        # Convert to dataframes\n",
    "        actual_df = pd.DataFrame(actual_data)\n",
    "        predicted_df = pd.DataFrame(predicted_data)\n",
    "        \n",
    "        # Check if data already exists for this location\n",
    "        with engine.connect() as conn:\n",
    "            actual_count = conn.execute(text(f\"SELECT COUNT(*) FROM taxi_rides WHERE pickup_location_id = {location_id}\")).fetchone()[0]\n",
    "            predicted_count = conn.execute(text(f\"SELECT COUNT(*) FROM predicted_rides WHERE pickup_location_id = {location_id}\")).fetchone()[0]\n",
    "        \n",
    "        # Insert data if none exists\n",
    "        if actual_count == 0:\n",
    "            actual_df.to_sql('taxi_rides', engine, if_exists='append', index=False)\n",
    "            print(f\"Added {len(actual_df)} actual rides for location {location_id}\")\n",
    "        else:\n",
    "            print(f\"Location {location_id} already has {actual_count} actual records\")\n",
    "            \n",
    "        if predicted_count == 0:\n",
    "            predicted_df.to_sql('predicted_rides', engine, if_exists='append', index=False)\n",
    "            print(f\"Added {len(predicted_df)} predicted rides for location {location_id}\")\n",
    "        else:\n",
    "            print(f\"Location {location_id} already has {predicted_count} predicted records\")\n",
    "    \n",
    "    print(\"Sample data generation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9489e9c4-9e47-4b44-a115-3e32df104b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717/2586488559.py:25: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  date_range = pd.date_range(start=start_date, end=end_date, freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 169 actual rides for location 43\n",
      "Location 43 already has 26352 predicted records\n",
      "Added 169 actual rides for location 74\n",
      "Added 169 predicted rides for location 74\n",
      "Added 169 actual rides for location 132\n",
      "Added 169 predicted rides for location 132\n",
      "Sample data generation complete!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    generate_sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d6a3f4e-9563-437a-b42c-384c4a2a4a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "eastern = ZoneInfo(\"America/New_York\")\n",
    "now_ny = datetime.now(tz=eastern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "235f5aad-f1ec-435c-a73c-70d507789c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now_ny.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2279e5-fa90-4da4-87d3-455d672e4a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
